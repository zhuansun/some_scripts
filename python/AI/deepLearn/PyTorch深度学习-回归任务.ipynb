{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据\n",
    "X, y = make_regression(n_samples=10000, n_features=100, n_informative=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 人为增加噪声\n",
    "np.random.seed(0)\n",
    "nosie = np.random.randn(10000) * 10\n",
    "y += nosie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆分数据集\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 给测试集人为增加噪声\n",
    "np.random.seed(1)\n",
    "nosie = np.random.randn(2000) * 10\n",
    "y_test += nosie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "mu = X_train.mean(axis=0)\n",
    "sigma = X_train.std(axis=0) + 1e-10\n",
    "X_train = (X_train - mu) / sigma\n",
    "X_test = (X_test - mu) / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "            初始化\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "            返回数据集中样本的总个数\n",
    "        \"\"\"\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "            用于索引数据\n",
    "        \"\"\"\n",
    "        x_idx = torch.tensor(data=self.X[idx], dtype=torch.float32)\n",
    "        y_idx = torch.tensor(data=[self.y[idx]], dtype=torch.float32)\n",
    "        return x_idx, y_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打包训练集\n",
    "train_dataset = MyDataset(X=X_train, y=y_train)\n",
    "# 定义一个数据集的加载器\n",
    "# shuffle 表示是否打乱数据\n",
    "# 如果数据集最后一批不够了，有两个策略，一种是丢弃，另一种是直接作为最后一批，通过drop_last=True来控制\n",
    "# 普通的生成器只能被遍历一次；dataloader也是一个生成器，但是可以被遍历多次\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打包测试集\n",
    "test_dataset = MyDataset(X=X_test, y=y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义模型\n",
    "from torch import nn\n",
    "# 模型继承自 nn.Module\n",
    "class Model(nn.Module):\n",
    "    \"\"\"自定义深度学习模型\"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"初始化\"\"\"\n",
    "        super(Model,self).__init__()\n",
    "        # 定义一个线性层，可以把100个特征变成了1个特征\n",
    "        self.fc1 = nn.Linear(in_features=100, out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        正向传播过程\n",
    "            - x: 输入数据，形状为(batch_size, 100)\n",
    "            - 返回值: 输出数据，形状为(batch_size, 1)\n",
    "        \"\"\"\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPS:模型是一个线性层，结果是怎么算出来的\\n- 我猜测和我们之前做的一样，第一次线性变换使用的 w和b是随机的。然后后续再不停地优化\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "PS:模型是一个线性层，结果是怎么算出来的\n",
    "- 我猜测和我们之前做的一样，第一次线性变换使用的 w和b是随机的。然后后续再不停地优化\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型\n",
    "model = Model()\n",
    "epochs = 100\n",
    "learning_rate = 1e-3\n",
    "loss_fn = nn.MSELoss()\n",
    "# 优化器\n",
    "# 优化器做了两个步骤：自动求偏导，清空梯度\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# 记录损失\n",
    "train_mses = []\n",
    "test_mses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 过程监控\n",
    "def get_mse(dataloader, model):\n",
    "    # 设置模型为评估模式\n",
    "    model.eval()\n",
    "    mses = []\n",
    "    with torch.no_grad():\n",
    "        for batch_x,batch_y in dataloader:\n",
    "            y_pred = model(batch_x)\n",
    "            loss = loss_fn(y_pred, batch_y)\n",
    "            mse = loss.item()\n",
    "            mses.append(mse)\n",
    "    return torch.tensor(mses).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"定义训练过程\"\"\"\n",
    "\n",
    "def train(\n",
    "        model=model, \n",
    "        dataloader = train_dataloader, \n",
    "        optimizer = optimizer,  \n",
    "        loss_fn=loss_fn,\n",
    "        epochs = epochs\n",
    "        ):\n",
    "    \n",
    "    train_mse = get_mse(dataloader=train_dataloader,model=model)\n",
    "    test_mse = get_mse(dataloader=test_dataloader,model=model)\n",
    "\n",
    "    train_mses.append(train_mse)\n",
    "    test_mses.append(test_mse)\n",
    "\n",
    "    print(f\"在训练之前，模型的在训练集和测试集上的损失为 {train_mse:.4f} {test_mse:.4f}\")\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # 设置为训练模式\n",
    "        model.train()\n",
    "        for batch_idx,(batch_X,batch_y) in enumerate(dataloader):\n",
    "            # print(f\"当前正在训练 {epoch+1} 轮 当前批次为 {batch_idx+1}\")\n",
    "            # 正向传播\n",
    "            y_pred = model(batch_X)\n",
    "            # 计算损失\n",
    "            loss = loss_fn(y_pred,batch_y)\n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            # 优化一步\n",
    "            optimizer.step()\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "        # 本轮训练完成之后，计算mse\n",
    "        train_mse = get_mse(dataloader=train_dataloader,model=model)\n",
    "        test_mse = get_mse(dataloader=test_dataloader,model=model)\n",
    "        train_mses.append(train_mse)\n",
    "        test_mses.append(test_mse)\n",
    "        print(f\"当前正在训练 {epoch+1} 轮 当前训练集损失为 {train_mse:.4f} 当前测试集损失为 {test_mse:.4f}\")\n",
    "        # print(f\"当前正在训练 {epoch+1} 轮 当前损失为 {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在训练之前，模型的在训练集和测试集上的损失为 42919.6172 40433.4531\n",
      "当前正在训练 1 轮 当前训练集损失为 632.1267 当前测试集损失为 771.1803\n",
      "当前正在训练 2 轮 当前训练集损失为 239.7838 当前测试集损失为 376.2807\n",
      "当前正在训练 3 轮 当前训练集损失为 134.4661 当前测试集损失为 269.8095\n",
      "当前正在训练 4 轮 当前训练集损失为 110.6756 当前测试集损失为 251.9476\n",
      "当前正在训练 5 轮 当前训练集损失为 98.6247 当前测试集损失为 238.9331\n",
      "当前正在训练 6 轮 当前训练集损失为 98.7212 当前测试集损失为 239.8329\n",
      "当前正在训练 7 轮 当前训练集损失为 94.8735 当前测试集损失为 244.8241\n",
      "当前正在训练 8 轮 当前训练集损失为 87.3571 当前测试集损失为 234.0539\n",
      "当前正在训练 9 轮 当前训练集损失为 89.7654 当前测试集损失为 244.0027\n",
      "当前正在训练 10 轮 当前训练集损失为 85.3544 当前测试集损失为 238.7961\n",
      "当前正在训练 11 轮 当前训练集损失为 84.2275 当前测试集损失为 239.1479\n",
      "当前正在训练 12 轮 当前训练集损失为 85.0104 当前测试集损失为 242.8803\n",
      "当前正在训练 13 轮 当前训练集损失为 82.4524 当前测试集损失为 241.8330\n",
      "当前正在训练 14 轮 当前训练集损失为 80.5790 当前测试集损失为 243.6412\n",
      "当前正在训练 15 轮 当前训练集损失为 81.4139 当前测试集损失为 247.7670\n",
      "当前正在训练 16 轮 当前训练集损失为 77.8616 当前测试集损失为 246.3548\n",
      "当前正在训练 17 轮 当前训练集损失为 77.2874 当前测试集损失为 238.5093\n",
      "当前正在训练 18 轮 当前训练集损失为 74.1866 当前测试集损失为 242.0536\n",
      "当前正在训练 19 轮 当前训练集损失为 75.9346 当前测试集损失为 241.5382\n",
      "当前正在训练 20 轮 当前训练集损失为 73.2551 当前测试集损失为 241.2853\n",
      "当前正在训练 21 轮 当前训练集损失为 71.5222 当前测试集损失为 243.6376\n",
      "当前正在训练 22 轮 当前训练集损失为 76.6544 当前测试集损失为 245.8726\n",
      "当前正在训练 23 轮 当前训练集损失为 72.8701 当前测试集损失为 245.5175\n",
      "当前正在训练 24 轮 当前训练集损失为 69.0877 当前测试集损失为 246.6832\n",
      "当前正在训练 25 轮 当前训练集损失为 65.2636 当前测试集损失为 241.2792\n",
      "当前正在训练 26 轮 当前训练集损失为 63.7818 当前测试集损失为 240.5486\n",
      "当前正在训练 27 轮 当前训练集损失为 68.4706 当前测试集损失为 246.1877\n",
      "当前正在训练 28 轮 当前训练集损失为 65.3163 当前测试集损失为 241.4569\n",
      "当前正在训练 29 轮 当前训练集损失为 67.1350 当前测试集损失为 246.5498\n",
      "当前正在训练 30 轮 当前训练集损失为 63.2206 当前测试集损失为 247.5590\n",
      "当前正在训练 31 轮 当前训练集损失为 64.6801 当前测试集损失为 247.2292\n",
      "当前正在训练 32 轮 当前训练集损失为 64.3954 当前测试集损失为 249.1971\n",
      "当前正在训练 33 轮 当前训练集损失为 64.4325 当前测试集损失为 246.9573\n",
      "当前正在训练 34 轮 当前训练集损失为 60.6342 当前测试集损失为 247.4646\n",
      "当前正在训练 35 轮 当前训练集损失为 60.8971 当前测试集损失为 249.7158\n",
      "当前正在训练 36 轮 当前训练集损失为 59.6986 当前测试集损失为 243.6858\n",
      "当前正在训练 37 轮 当前训练集损失为 59.6779 当前测试集损失为 249.8038\n",
      "当前正在训练 38 轮 当前训练集损失为 63.2636 当前测试集损失为 250.7433\n",
      "当前正在训练 39 轮 当前训练集损失为 60.4133 当前测试集损失为 245.0811\n",
      "当前正在训练 40 轮 当前训练集损失为 57.4031 当前测试集损失为 250.1429\n",
      "当前正在训练 41 轮 当前训练集损失为 58.1740 当前测试集损失为 249.6318\n",
      "当前正在训练 42 轮 当前训练集损失为 57.1043 当前测试集损失为 248.2737\n",
      "当前正在训练 43 轮 当前训练集损失为 57.5539 当前测试集损失为 251.4634\n",
      "当前正在训练 44 轮 当前训练集损失为 56.2901 当前测试集损失为 249.8459\n",
      "当前正在训练 45 轮 当前训练集损失为 56.5292 当前测试集损失为 251.1251\n",
      "当前正在训练 46 轮 当前训练集损失为 54.6795 当前测试集损失为 247.0868\n",
      "当前正在训练 47 轮 当前训练集损失为 55.7180 当前测试集损失为 247.7020\n",
      "当前正在训练 48 轮 当前训练集损失为 53.2973 当前测试集损失为 252.6052\n",
      "当前正在训练 49 轮 当前训练集损失为 54.7249 当前测试集损失为 251.3531\n",
      "当前正在训练 50 轮 当前训练集损失为 53.6929 当前测试集损失为 250.5323\n",
      "当前正在训练 51 轮 当前训练集损失为 52.6728 当前测试集损失为 248.8710\n",
      "当前正在训练 52 轮 当前训练集损失为 50.8131 当前测试集损失为 252.3117\n",
      "当前正在训练 53 轮 当前训练集损失为 55.3704 当前测试集损失为 256.0526\n",
      "当前正在训练 54 轮 当前训练集损失为 53.5567 当前测试集损失为 254.7030\n",
      "当前正在训练 55 轮 当前训练集损失为 50.9206 当前测试集损失为 253.8442\n",
      "当前正在训练 56 轮 当前训练集损失为 53.6675 当前测试集损失为 259.9295\n",
      "当前正在训练 57 轮 当前训练集损失为 52.3157 当前测试集损失为 256.6748\n",
      "当前正在训练 58 轮 当前训练集损失为 48.7763 当前测试集损失为 256.4821\n",
      "当前正在训练 59 轮 当前训练集损失为 50.3042 当前测试集损失为 256.4554\n",
      "当前正在训练 60 轮 当前训练集损失为 51.0461 当前测试集损失为 256.7143\n",
      "当前正在训练 61 轮 当前训练集损失为 49.9935 当前测试集损失为 254.3471\n",
      "当前正在训练 62 轮 当前训练集损失为 48.3795 当前测试集损失为 252.0203\n",
      "当前正在训练 63 轮 当前训练集损失为 48.5849 当前测试集损失为 255.6305\n",
      "当前正在训练 64 轮 当前训练集损失为 48.0137 当前测试集损失为 252.8258\n",
      "当前正在训练 65 轮 当前训练集损失为 46.4450 当前测试集损失为 255.9484\n",
      "当前正在训练 66 轮 当前训练集损失为 46.5719 当前测试集损失为 258.8785\n",
      "当前正在训练 67 轮 当前训练集损失为 45.0559 当前测试集损失为 255.1958\n",
      "当前正在训练 68 轮 当前训练集损失为 46.7691 当前测试集损失为 257.7529\n",
      "当前正在训练 69 轮 当前训练集损失为 46.3934 当前测试集损失为 260.2072\n",
      "当前正在训练 70 轮 当前训练集损失为 44.1331 当前测试集损失为 259.9220\n",
      "当前正在训练 71 轮 当前训练集损失为 47.2139 当前测试集损失为 263.0139\n",
      "当前正在训练 72 轮 当前训练集损失为 45.2366 当前测试集损失为 257.9851\n",
      "当前正在训练 73 轮 当前训练集损失为 46.1055 当前测试集损失为 262.0931\n",
      "当前正在训练 74 轮 当前训练集损失为 43.1707 当前测试集损失为 256.9554\n",
      "当前正在训练 75 轮 当前训练集损失为 42.5957 当前测试集损失为 259.5349\n",
      "当前正在训练 76 轮 当前训练集损失为 41.9082 当前测试集损失为 257.3611\n",
      "当前正在训练 77 轮 当前训练集损失为 44.0687 当前测试集损失为 258.4728\n",
      "当前正在训练 78 轮 当前训练集损失为 42.1839 当前测试集损失为 256.5737\n",
      "当前正在训练 79 轮 当前训练集损失为 42.1802 当前测试集损失为 258.4580\n",
      "当前正在训练 80 轮 当前训练集损失为 42.9049 当前测试集损失为 262.8675\n",
      "当前正在训练 81 轮 当前训练集损失为 43.4312 当前测试集损失为 261.9259\n",
      "当前正在训练 82 轮 当前训练集损失为 40.3779 当前测试集损失为 259.9267\n",
      "当前正在训练 83 轮 当前训练集损失为 40.5825 当前测试集损失为 262.1539\n",
      "当前正在训练 84 轮 当前训练集损失为 40.7436 当前测试集损失为 262.9536\n",
      "当前正在训练 85 轮 当前训练集损失为 40.7781 当前测试集损失为 261.6815\n",
      "当前正在训练 86 轮 当前训练集损失为 40.8285 当前测试集损失为 265.1523\n",
      "当前正在训练 87 轮 当前训练集损失为 38.9020 当前测试集损失为 265.3236\n",
      "当前正在训练 88 轮 当前训练集损失为 39.3477 当前测试集损失为 262.8375\n",
      "当前正在训练 89 轮 当前训练集损失为 40.9725 当前测试集损失为 264.2820\n",
      "当前正在训练 90 轮 当前训练集损失为 39.1986 当前测试集损失为 262.4605\n",
      "当前正在训练 91 轮 当前训练集损失为 37.9924 当前测试集损失为 264.1260\n",
      "当前正在训练 92 轮 当前训练集损失为 42.4797 当前测试集损失为 268.6269\n",
      "当前正在训练 93 轮 当前训练集损失为 37.8552 当前测试集损失为 263.1822\n",
      "当前正在训练 94 轮 当前训练集损失为 42.0281 当前测试集损失为 268.1174\n",
      "当前正在训练 95 轮 当前训练集损失为 38.7016 当前测试集损失为 265.2980\n",
      "当前正在训练 96 轮 当前训练集损失为 36.9402 当前测试集损失为 266.5318\n",
      "当前正在训练 97 轮 当前训练集损失为 40.0108 当前测试集损失为 266.7664\n",
      "当前正在训练 98 轮 当前训练集损失为 36.4578 当前测试集损失为 263.6619\n",
      "当前正在训练 99 轮 当前训练集损失为 36.7522 当前测试集损失为 266.9186\n",
      "当前正在训练 100 轮 当前训练集损失为 36.5269 当前测试集损失为 267.3790\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 画图\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a6242430>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGdCAYAAADwjmIIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAvz0lEQVR4nO3dC5RU1Z3v8f+p6gcgNM+BFgEhwYg8BAFBopNcI2PH4SYxsGbQMUoQ46jogOSCYaIwycRpllwTX4hxvFHvispjrUHDQx0uLyex5RkUEIm5ksAVG3ykuxGh6a6z79q7zjld1XRro733oau+n2VZfap2nbNrd1Xx6/045SmllAAAAOSYRNwVAAAAsIGQAwAAchIhBwAA5CRCDgAAyEmEHAAAkJMIOQAAICcRcgAAQE4i5AAAgJxUIHnM9305dOiQdOrUSTzPi7s6AACgBfR5jI8ePSq9e/eWRKL5/pq8Djk64PTt2zfuagAAgM/h4MGD0qdPn2bvz+uQo3twwkYqKSmJuzoAAKAFampqTCdF+O94c/I65IRDVDrgEHIAAGhbPmuqCROPAQBATiLkAACAnETIAQAAOYmQAwAAchIhBwAA5CRCDgAAyEmEHAAAkJMIOQAAICcRcgAAQE4i5AAAgJxEyAEAADmJkAMAAHJSXn9Bpy33/+c+qTleJ7f+t4FS2rld3NUBACAv0ZNjwZKtB+Xpij/Lh8dq464KAAB5i5BjQTL46nffj7smAADkL0KOBclEOuSklIq7KgAA5C1Cjs2QQ1cOAACxIeRYUBCFnLhrAgBA/iLkWJAIQk49PTkAAMSGkGOxJ4eMAwBAfAg5FiSC1VX05AAAEB9CjgUFyaAnh9VVAADEhpBjsycnRcgBACAuhBybc3LoyQEAIDaEHKurqwg5AADEhZBj9Tw5hBwAAOJCyLF6xmNCDgAAcSHkWEDIAQAgfoQci99CTsgBACA+hBwL+BZyAADiR8ixgOEqAADiR8ixoETVyF9Jlfj1J+OuCgAAeesLhZwFCxaI53kyc+bM6LYTJ07I9OnTpXv37tKxY0eZNGmSHD58OOtxBw4ckAkTJkiHDh2kZ8+eMnv2bKmvr88qs3HjRhk5cqQUFxfLwIED5amnnjrl+IsWLZL+/ftLu3btZOzYsbJlyxY5E9z9p6mytd1t0unj/XFXBQCAvPW5Q87WrVvll7/8pVx44YVZt995552ycuVKWb58uWzatEkOHTokEydOjO5PpVIm4Jw8eVJeffVVefrpp02AmTdvXlRm//79pszll18uO3fuNCHqpptukpdffjkqs3TpUpk1a5bMnz9fduzYIcOHD5eysjI5cuSIxM33kuZapbKDGwAAcEh9DkePHlXnnXeeWrt2rfr617+uZsyYYW6vqqpShYWFavny5VHZvXv36okpqqKiwmyvWbNGJRIJVVlZGZVZvHixKikpUbW1tWZ7zpw5asiQIVnHnDx5siorK4u2x4wZo6ZPnx5tp1Ip1bt3b1VeXt7i51FdXW3qpq9b00c/O0+p+SVq6QsvtOp+AQCAavG/35+rJ0cPR+melvHjx2fdvn37dqmrq8u6fdCgQdKvXz+pqKgw2/p62LBh0qtXr6iM7oGpqamRPXv2RGUa71uXCfehe4H0sTLLJBIJsx2WaUptba05TubFZk+O0JMDAEBsCk73AUuWLDHDQ3q4qrHKykopKiqSLl26ZN2uA42+LyyTGXDC+8P7Pq2MDiXHjx+Xv/zlL2bYq6kyb731VrN1Ly8vl5/85CdimwpGAZVPyAEAIC6n1ZNz8OBBmTFjhjzzzDNmsm9bM3fuXKmuro4u+vnY4CeC7OinrOwfAAC0csjRQ0R6Yq9e9VRQUGAuenLxQw89ZH7WPSl6KKmqqirrcXp1VWlpqflZXzdebRVuf1aZkpISad++vfTo0UOSyWSTZcJ9NEWv1NL7yLzYoMKJx/TkAADQNkLOFVdcIbt27TIrnsLL6NGj5brrrot+LiwslHXr1kWP2bdvn1kyPm7cOLOtr/U+MldBrV271gSOwYMHR2Uy9xGWCfehh8RGjRqVVcb3fbMdlolTOFzFnBwAANrInJxOnTrJ0KFDs24766yzzDlxwtunTZtmlnZ369bNBJc77rjDBI9LLrnE3H/llVeaMHP99dfLfffdZ+bf3H333WYys+5p0W655RZ55JFHZM6cOXLjjTfK+vXrZdmyZbJ69erouPoYU6ZMMcFqzJgx8sADD8ixY8dk6tSpEjcVDFfRkwMAQBuaePxZfvGLX5iVTvokgHo1k14V9eijj0b362GmVatWya233mrCjw5JOqz89Kc/jcoMGDDABBp9zp0HH3xQ+vTpI0888YTZV2jy5Mny/vvvm/Pr6KA0YsQIeemll06ZjByHaHUVc3IAAIiNp9eRS57Sq7U6d+5sJiG35vyc/3f/16TP0dfluf73yrXfv73V9gsAAKTF/37z3VU2hD05iuEqAADiQsixOScn5cddFQAA8hYhx+IScnpyAACIDyHHhkQ65HisrgIAIDaEHJs9OayuAgAgNoQci3NyRBFyAACICyHHBoarAACIHSHHhmjiMT05AADEhZBjQzBc5TEnBwCA2BByrM7JYbgKAIC4EHIs8BLpZqUnBwCA+BBybAh6chLMyQEAIDaEHBu8YLiKnhwAAGJDyLE58ZieHAAAYkPIsXmeHCYeAwAQG0KOBV4y7MnhW8gBAIgLIcfqcBU9OQAAxIWQY4EXDFexugoAgPgQcmxgCTkAALEj5FiQiObkEHIAAIgLIccGenIAAIgdIccC5uQAABA/Qo7NJeRCyAEAIC6EHItzchKcJwcAgNgQcizwojk5nCcHAIC4EHIsDlclGa4CACA2hByLPTl8rQMAAPEh5Fick0NPDgAA8SHkWByuYgk5AADxIeTYXF0lDFcBABAXQo7V4SpflFJxVwcAgLxEyLEgEUw8LpCUpHxCDgAAcSDkWJAoaJh4XE/IAQAgFoQcq+fJUeIzXAUAQCwIORYkk4Xpa4arAACIDSHHgkQy/S3kzMkBACA+hBwLEkFPjl5CTsgBACAehByLIaeAkAMAQGwIOTYk0s2a9FKSYuIxAACxIOTYEJ0nx5f6FCEHAIA4EHIshhw9J4cl5AAAxIOQY0PGGY85GSAAAPEg5NjgBXNydE8OIQcAgFgQciz25OiQQ08OAADxIORYDTmcDBAAgLgQcmxIcMZjAADiRsix2ZPjKUn5fty1AQAgLxFyLPbkaKlUfaxVAQAgXxFyLPbkaD4hBwCAWBBybPAaenL8+rpYqwIAQL4i5FjvyUnFWhUAAPIVIcd6yKEnBwCAOBByLH4LuaaYkwMAQCwIOZbUS3peDqurAACIByHHEj8IOcon5AAAEAdCjiWpYIUVS8gBAIgHIccSP2ha5uQAABAPQo4lPj05AADEipBjeU6OEHIAAIgFIccS30s3LT05AADEg5BjebhKKUIOAABxIORY4nvpsx6rekIOAABxIOTYPk+O4rurAACIAyHHEhXMyWHiMQAA8SDk2F5CzhmPAQCIBSHHEhWEHCHkAAAQC0KO5ZCjUszJAQAgDoQcy8NV9OQAANAGQs7ixYvlwgsvlJKSEnMZN26cvPjii9H9J06ckOnTp0v37t2lY8eOMmnSJDl8+HDWPg4cOCATJkyQDh06SM+ePWX27NlS32iZ9caNG2XkyJFSXFwsAwcOlKeeeuqUuixatEj69+8v7dq1k7Fjx8qWLVvkTKLCJeSEHAAAzvyQ06dPH1mwYIFs375dtm3bJt/4xjfkO9/5juzZs8fcf+edd8rKlStl+fLlsmnTJjl06JBMnDgxenwqlTIB5+TJk/Lqq6/K008/bQLMvHnzojL79+83ZS6//HLZuXOnzJw5U2666SZ5+eWXozJLly6VWbNmyfz582XHjh0yfPhwKSsrkyNHjsiZQiXCnhyGqwAAiIX6grp27aqeeOIJVVVVpQoLC9Xy5cuj+/bu3av0ISoqKsz2mjVrVCKRUJWVlVGZxYsXq5KSElVbW2u258yZo4YMGZJ1jMmTJ6uysrJoe8yYMWr69OnRdiqVUr1791bl5eWnVffq6mpTP33d2t65/xtKzS9RK57+eavvGwCAfFbdwn+/P/ecHN0rs2TJEjl27JgZttK9O3V1dTJ+/PiozKBBg6Rfv35SUVFhtvX1sGHDpFevXlEZ3QNTU1MT9QbpMpn7CMuE+9C9QPpYmWUSiYTZDss0p7a21hwr82J/uMq3dgwAANC80w45u3btMvNt9HyZW265RVasWCGDBw+WyspKKSoqki5dumSV14FG36fp68yAE94f3vdpZXQgOX78uHzwwQcmYDVVJtxHc8rLy6Vz587RpW/fvmILS8gBAGhjIef88883c2U2b94st956q0yZMkXefPNNaQvmzp0r1dXV0eXgwYP2DhbMyfH4gk4AAGKRHlM5Dbq3Rq940kaNGiVbt26VBx98UCZPnmyGkqqqqrJ6c/TqqtLSUvOzvm68CipcfZVZpvGKLL2tV3O1b99eksmkuTRVJtxHc3Tvk764QE8OAABt/Dw5vu+buS468BQWFsq6deui+/bt22eWjOs5O5q+1sNdmaug1q5dawKMHvIKy2TuIywT7kOHLH2szDK6Dno7LHMmUIkgP7K6CgCAM78nRw/3XHXVVWYy8dGjR+XZZ58157TRy7v1HJdp06aZpd3dunUzweWOO+4wweOSSy4xj7/yyitNmLn++uvlvvvuM3No7r77bnNunbCHRc/zeeSRR2TOnDly4403yvr162XZsmWyevXqqB76GHqYbPTo0TJmzBh54IEHzAToqVOnyhmDkAMAQNsJOboH5oYbbpD33nvPhBp9YkAdcP7mb/7G3P+LX/zCrHTSJwHUvTt6VdSjjz4aPV4PM61atcrM5dHh56yzzjJh5ac//WlUZsCAASbQ6HPu6GEwfW6eJ554wuwrpIfG3n//fXN+HR2URowYIS+99NIpk5FjFXwLucdwFQAAsfD0OnLJU3rFlg5rehKy7nlqTX/45Q3ylfdekOd73CxX376wVfcNAEA+q2nhv998d5UtyXQnWYLVVQAAxIKQY3m4ijk5AADEg5BjeeIx58kBACAehBxbWF0FAECsCDmWQ05CEXIAAIgDIccSL/xaB3pyAACIBSHHliDkCD05AADEgpBjC8NVAADEipBje7iKkAMAQCwIOdZ7clhCDgBAHAg5lnjBGY895cddFQAA8hIhxxbm5AAAECtCjiXMyQEAIF6EHEs8enIAAIgVIcfynJyEEHIAAIgDIcd2yKEnBwCAWBByLEkwXAUAQKwIObaXkAtLyAEAiAMhx3LISdKTAwBALAg5liSS6SXkTDwGACAehBxLvEShuU5wxmMAAGJByLEkkUyHnCQ9OQAAxIKQY0kimW5ahqsAAIgHIceSRLLIXDPxGACAeBByLPGiicfMyQEAIA6EHEuSBek5OQWSEt9XcVcHAIC8Q8ixfMbjpPhST8gBAMA5Qo4liYKGkOMrQg4AAK4RcmwvIfdS9OQAABADQo4lyWDicYH4kiLkAADgHCHHwckACTkAALhHyLEkEX5BJz05AADEgpBj+1vICTkAAMSCkGOLF87JSUmK1VUAADhHyLElOE+OPuNxKkXIAQDANUKO5ZBDTw4AAPEg5NiSSA9XJT0lqVR93LUBACDvEHIshxwtVc83kQMA4Bohx/JwlZZK1cVaFQAA8hEhx0HIUSl6cgAAcI2QY3kJuZaqPxlrVQAAyEeEHAc9Ob5PTw4AAK4RcmxJ6DPkeObHVD1zcgAAcI2QY5EfNK/yWUIOAIBrhByLUpKel+PXE3IAAHCNkOMi5NCTAwCAc4Qci3wvGK7ijMcAADhHyLHID3tyCDkAADhHyLEoFZwrh4nHAAC4R8ixiJ4cAADiQ8ixiDk5AADEh5DjoCeHkAMAgHuEHIv8YE4OX+sAAIB7hBwHIUfoyQEAwDlCjkUqnJPD6ioAAJwj5DjoySHkAADgHiHHIl8KzDUTjwEAcI+QYxHDVQAAxIeQY5GKJh6zugoAANcIORb5XjBcRU8OAADOEXIsUomgJ4fz5AAA4BwhxyLm5AAAEB9CjkUqGK6iJwcAAPcIOS4mHtOTAwCAc4Qcm6I5OYQcAABcI+S4+O4qhqsAAHCOkGNTIpiTowg5AACc0SGnvLxcLr74YunUqZP07NlTrr76atm3b19WmRMnTsj06dOle/fu0rFjR5k0aZIcPnw4q8yBAwdkwoQJ0qFDB7Of2bNnS3199pDOxo0bZeTIkVJcXCwDBw6Up5566pT6LFq0SPr37y/t2rWTsWPHypYtW+RMwpwcAADaSMjZtGmTCTCvvfaarF27Vurq6uTKK6+UY8eORWXuvPNOWblypSxfvtyUP3TokEycODG6P5VKmYBz8uRJefXVV+Xpp582AWbevHlRmf3795syl19+uezcuVNmzpwpN910k7z88stRmaVLl8qsWbNk/vz5smPHDhk+fLiUlZXJkSNH5IxByAEAID7qCzhy5IjSu9i0aZPZrqqqUoWFhWr58uVRmb1795oyFRUVZnvNmjUqkUioysrKqMzixYtVSUmJqq2tNdtz5sxRQ4YMyTrW5MmTVVlZWbQ9ZswYNX369Gg7lUqp3r17q/Ly8hbXv7q62tRNX9uwe/EUpeaXqBcX/dDK/gEAyEfVLfz3+wvNyamurjbX3bp1M9fbt283vTvjx4+PygwaNEj69esnFRUVZltfDxs2THr16hWV0T0wNTU1smfPnqhM5j7CMuE+dC+QPlZmmUQiYbbDMk2pra01x8m82KSCOTmeoicHAADXPnfI8X3fDCNdeumlMnToUHNbZWWlFBUVSZcuXbLK6kCj7wvLZAac8P7wvk8ro0PJ8ePH5YMPPjDDXk2VCffR3Jyizp07R5e+ffuKVYl083qsrgIAoO2EHD03Z/fu3bJkyRJpK+bOnWt6n8LLwYMH7R4wOOMxPTkAALgXrHE+PbfffrusWrVKXnnlFenTp090e2lpqRlKqqqqyurN0aur9H1hmcaroMLVV5llGq/I0tslJSXSvn17SSaT5tJUmXAfTdErtfTF+ckAWUIOAMCZ3ZOjlDIBZ8WKFbJ+/XoZMGBA1v2jRo2SwsJCWbduXXSbXmKul4yPGzfObOvrXbt2Za2C0iu1dIAZPHhwVCZzH2GZcB96SEwfK7OMHj7T22GZM0I4J4fhKgAAzuyeHD1E9eyzz8oLL7xgzpUTzn/R81t0D4u+njZtmlnarScj6+Byxx13mOBxySWXmLJ6ybkOM9dff73cd999Zh9333232XfYy3LLLbfII488InPmzJEbb7zRBKply5bJ6tWro7roY0yZMkVGjx4tY8aMkQceeMAsZZ86daqcMYKeHI+eHAAA3DudJVu6eFOXJ598Mipz/Phxddttt6muXbuqDh06qO9+97vqvffey9rPn/70J3XVVVep9u3bqx49eqgf/vCHqq6uLqvMhg0b1IgRI1RRUZH60pe+lHWM0MMPP6z69etnyugl5a+99trpPB3rS8h3/fous4R83f/8npX9AwCQj6pb+O+3p/8neUqv1tK9T3oSsu51am27n7tbhu57WDZ0nCCX/49nW33/AADko5oW/vvNd1dZ5IXDVZzxGAAA5wg5DiYeJ5iTAwCAc4Qci7zojMeEHAAAXCPk2JQk5AAAEBdCjoM5OQxXAQDgHiHHyXCVH3dVAADIO4Qci7xguCohrK4CAMA1Qo5FDFcBABAfQo6D4SpCDgAA7hFyLEoUFJprT5iTAwCAa4Qcm+jJAQAgNoQcixLBnJwkIQcAAOcIORYlwpMBMlwFAIBzhBwHS8jpyQEAwD1CjoOenKQQcgAAcI2Q4+RkgIQcAABcI+RYlEiml5An+FoHAACcI+RYxHAVAADxIeRYlEgGS8gJOQAAOEfIsSgZDlexhBwAAOcIORZ5BenhqgLxRSkVd3UAAMgrhByLkhlzclI+IQcAAJcIOU4mHvtST8gBAMApQo5FyeBbyHXI8RmuAgDAKUKORV4w8bhAUvTkAADgGCHHooKMJeQ+IQcAAKcIOY6Gq+jJAQDALUKORV4iCDmeEj/FCQEBAHCJkGNToqF56+vrY60KAAD5hpBjUyK9hFxLpQg5AAC4RMhxFHIUIQcAAKcIOc56cupirQoAAPmGkGOTl15CrvnMyQEAwClCjk0J/f3jnvmROTkAALhFyLEsJeneHJ+QAwCAU4Qcy/ygif165uQAAOASIceyVBhyfE4GCACAS4QcZ8NV9OQAAOASIceyVLDCivPkAADgFiHH1ZwcQg4AAE4RcizzWV0FAEAsCDmWMVwFAEA8CDmOhqsIOQAAuEXIscwPenJSPiEHAACXCDmOQo4QcgAAcIqQYxkTjwEAiAchxzIV9uQQcgAAcIqQ42h1FV/rAACAW4Qcy+jJAQAgHoQcV0vImXgMAIBThBzLlFeQvma4CgAApwg5jpaQK76FHAAApwg5lqlEeJ4cenIAAHCJkONq4rFPTw4AAC4RchyFHOX7cVcFAIC8Qshx1pPD6ioAAFwi5FhGyAEAIB6EHEcTj1lCDgCAW4QcR+fJ8RQ9OQAAuETIsYyeHAAA4kHIsS2Yk+MxJwcAAKcIOZapRHq4SlhCDgCAU4QcZz05nAwQAACXCDm2hUvIFXNyAABwiZDjariKkAMAgFOEHNuC1VUeq6sAAHCKkGNb0JPDeXIAADjDQ84rr7wi3/rWt6R3797ieZ48//zzWfcrpWTevHly9tlnS/v27WX8+PHy9ttvZ5X56KOP5LrrrpOSkhLp0qWLTJs2TT7++OOsMm+88Yb89V//tbRr10769u0r99133yl1Wb58uQwaNMiUGTZsmKxZs0bONB49OQAAtI2Qc+zYMRk+fLgsWrSoyft1GHnooYfksccek82bN8tZZ50lZWVlcuLEiaiMDjh79uyRtWvXyqpVq0xwuvnmm6P7a2pq5Morr5Rzzz1Xtm/fLgsXLpR/+Zd/kccffzwq8+qrr8q1115rAtLvf/97ufrqq81l9+7dciae8Zg5OQAAOKa+AP3wFStWRNu+76vS0lK1cOHC6LaqqipVXFysnnvuObP95ptvmsdt3bo1KvPiiy8qz/PUu+++a7YfffRR1bVrV1VbWxuVueuuu9T5558fbf/93/+9mjBhQlZ9xo4dq/7xH/+xxfWvrq42ddHXtmz/9d1KzS9Rv7t/srVjAACQT6pb+O93q87J2b9/v1RWVpohqlDnzp1l7NixUlFRYbb1tR6iGj16dFRGl08kEqbnJyzzta99TYqKiqIyujdo37598pe//CUqk3mcsEx4nKbU1taaXqLMi3XBcBXfQg4AgFutGnJ0wNF69eqVdbveDu/T1z179sy6v6CgQLp165ZVpql9ZB6juTLh/U0pLy83oSu86Lk+riYeJxRnPAYAwKW8Wl01d+5cqa6uji4HDx50uLqKOTkAALTZkFNaWmquDx8+nHW73g7v09dHjhzJur++vt6suMos09Q+Mo/RXJnw/qYUFxebFV2ZF9s8lpADAND2Q86AAQNMyFi3bl10m573oufajBs3zmzr66qqKrNqKrR+/Xrxfd/M3QnL6BVXdXUN3/ekV2Kdf/750rVr16hM5nHCMuFxzhReMj0nJ0FPDgAAZ3bI0eez2blzp7mEk431zwcOHDDnzZk5c6b87Gc/k9/85jeya9cuueGGG8w5dfTybu2CCy6Qb37zm/KDH/xAtmzZIr/73e/k9ttvl2uuucaU0/7hH/7BTDrWy8P1UvOlS5fKgw8+KLNmzYrqMWPGDHnppZfk/vvvl7feesssMd+2bZvZ15mkoSeHOTkAADh1usu2NmzYYJZtNb5MmTIlWkZ+zz33qF69epml41dccYXat29f1j4+/PBDde2116qOHTuqkpISNXXqVHX06NGsMq+//rq67LLLzD7OOecctWDBglPqsmzZMvWVr3xFFRUVqSFDhqjVq1ef1nNxsYR858pHzRLyHfd+w9oxAADIJ9Ut/Pfb0/+TPKWH0vQqKz0J2db8nDfWPC4XbpktOwtHyIgfb7JyDAAA8klNC//9zqvVVXHwksEScmG4CgAAlwg5rkIOE48BAHCKkONo4jEhBwAAtwg5liXoyQEAIBaEHFc9OczJAQDAKUKOZYmCMOTQkwMAgEuEHMu84FvIkwxXAQDgFCHHskSyMH3NcBUAAE4RcixjCTkAAPEg5FiWDHpykszJAQDAKUKOZYngW8gJOQAAuEXIcXYyQObkAADgEiHHskQBw1UAAMSBkONsuIqeHAAAXCLkWJZMFqWvCTkAADhFyLHMK2DiMQAAcSDkOOvJSYnvq7irAwBA3iDkWJYMvtahQHypJ+QAAOAMIceyRGHwtQ6eEt9nyAoAAFcIOY7OeKzV19fHWhcAAPIJIceyZLCEXEvV18VaFwAA8gkhx7JkcDJALZWiJwcAAFcIOZYlgm8h13yGqwAAcIaQ4+i7q7RUiuEqAABcIeTYlkiIrzzzo89wFQAAzhByHKgPmpnhKgAA3CHkOJCS9AorenIAAHCHkOOA76WbOZU6GXdVAADIG4Qcpz05fBM5AACuEHKchhx6cgAAcIWQ40AqaGZVz3dXAQDgCiHHAT/oyeE8OQAAuEPIcSAVTDxWPqurAABwhZDjsCeHJeQAALhDyHHA9wg5AAC4RshxwA8nHjNcBQCAM4QcB1JBT46iJwcAAGcIOQ4o5uQAAOAcIcfhnBx6cgAAcIeQ4zLk+JwMEAAAVwg5TkMOPTkAALhCyHG5uorhKgAAnCHkOKDoyQEAwDlCjgO+VxD8QMgBAMAVQo4DKvzuqhQTjwEAcIWQ43C4ip4cAADcIeQ4HK5iCTkAAO4QchxQCXpyAABwjZDjAMNVAAC4R8hxuoSc4SoAAFwh5DhATw4AAO4RclxgTg4AAM4Rcpz25DBcBQCAK4QcB1QiOOOxIuQAAOAKIccB5uQAAOAeIcfhnByP4SoAAJwh5Digwi/oZLgKAABnCDlOe3IYrgIAwBVCjgMeq6sAAHCOkONwdZWn6MkBAMAVQo4LYcjx/bhrAgBA3iDkuEBPDgAAzhFyHPAS6Wb2WF0FAIAzhBwXEoXpa0IOAADOEHIcLiFPEHIAAHCGkONCQZG5+vInb4j88f/EXRsAAPICIceBwz0vk//rny0lfpXIryeJrJolcvJY3NUCACCnEXIcGDlkiHy/6H55sr4sfcO2/yVq8aUi72wUqT8Zd/UAAMhJnlJKSRu2aNEiWbhwoVRWVsrw4cPl4YcfljFjxrTosTU1NdK5c2eprq6WkpISq/Ws+uSkzHthj3yw6z9lYeEv5RzvQ3O7ShSK91fni5QOE+k1RKRDd5GCYpGC9sF1sUiySCRZmJ7ArH/2PJGsX5tKn01Z+Q0XPQ9Il9fL15MFeolX+lvQU/Xp6/ArJnQ5fV94yWSOodLX4X4z6XpE5YJ6RI8J6yLZjzOP8cx/os8Eretn6hCcFTp6bLCfUwTHzK5oo+M2rk8T5Zv40dRNt0Fmm5zyUD+jrfUcq+Ax0cXL/j2YcyMFB/nMt1rG88h8vmGbferzVtnPwbRtUCdTX10mFZx1u4n6hPU3zz3j95r5XJoU1i/4OfN30OTvPfM108TxTZs38Vwz69G4PpntE9WlifaLjp1RP7OfzOfZqO2jq0b7Dx9v2jZ4PYTHCJ9Ds7+3Fsh8n5zyHBq3c/i7D8uGr8NG74nG7+dT2j5z32GZxq+xJl7Dje8P9x3tN3g/nfLaUI3eO8mmX9Nhe2S9Npp4b2e2UbOfSc18ljW1j1OOlXnMZj6bTnnvNPc51ugxp3yWNle3RmUav0f1JfoMCNs+aI+oTDg3tNHrNeu5flqVM14rWZ93jV5XmYZOFClsL62ppf9+B98c2TYtXbpUZs2aJY899piMHTtWHnjgASkrK5N9+/ZJz5495UzSpUORPHTtRbJ6SKlcs+Ircmvd0/Lfk5ulxP9E5PDu9AUAgFwzcHyrh5y86MnRwebiiy+WRx55xGz7vi99+/aVO+64Q370ox+dUT05mY4cPSHzX9gja9+slF7++3JB4oAM9v4sX0kclI5yQoqlToq9k+lrqZMCSUmhVy9FUi+F0nBCQZXxV2JKEmY7vE6KLwWmfMr8rC91kjRb9eZalxNJipKE+MGjTn0p6Ft9c0+6fHhMz0uXDf7uy6iLFzwmXT68DkuGfx/pEmG99PF1jcLjZV4yZdev4T4V/AWr6xkeP/z7SZk7M/8iD/eT3oieT7CHsB10vcK/wMLj6jK6RGZba+mt9HPRZcO9+F54TyLj76Sm/7JveGaeKK+hhp5qaI2Gts/+/WS2W7o+QS2Dx+r9pevUUPfsx6us55BQflCH9O9dP4/Grd/4d2JK6z/k9B92Wa+V8BUS/mYanmvm/eErLHz1NO4BaXhN6fbJrk/DT8Fx9Eea56Wvo/szXoVe9tEanmv26y5zv5l9VaH0K1e3T3p/Dc9Rt4U6pVOp6RY89TVhygW/u6x9ZlzCttAH0T9nlmt4bPq5NbT8qc81PIZ+JmG9G7dJVMfgtsyahscNb294v6fv1a840zrRayo8UvjeCbfC113mK6XxOzX79ZPVdlF7Z76js9/B+nWT9Xtv8veceWRp8rk39x5u/Jj06zTzdZ5R1jyRjN9x0D7NvR7Sr+X067qhdYN3ixf99jI+A9Jt7gW/kegn/XpJN7IkovZKt0r69dDwfMMGTNcw+72QPmJ6O/xdptu36d7L0qn/Wzp1bd2Oh5zvyTl58qRs375d5s6dG92WSCRk/PjxUlFR0eRjamtrzSWzkeLQs1M7Wfy9UVJbn5I/HvlY9r53VPa+VyNLDx+VmhP1cvxkvRyvS8nxkyk5UedLXcqXel9Jym+zeRQAkKe2FJRIp5iO3WZDzgcffCCpVEp69eqVdbvefuutt5p8THl5ufzkJz+RM0VxQVKG9O5sLi3h+0rqfL/JIVN9m2/+ChMThnTZlGq41rd5nmfSu87r4TCtfox5XPBzuC9z3fxMENEdgOnM1fCYKOtn/sGRcZuunZ6iEh6nqfvD/YR1MkPGQRldf33c9PHTxw7Lp6ccpO9LBM8zkdDX4V8nDXXOfL7h43QbZR8743lltEfSDEc37DezPcLnYO4Jpx1l1bnh+evbG55X07/Pz2r3T8u8DXU+tZA+snkdmEt2+6TbJft3Ed7eVD0b//4anlXjume/tpqvb/p4ul7pumbfHr7kso6V8RoJy2b+kNkGWa+X4DlGrxfdFkGbND5Wc4/T5cP3VHis8LlktWPwewvbMN1hkf0cs9sru3Ey31st6XzPKh/9rFr0egk/H9JVPLV2me+N8DPH/HWf0X6Zr6mwbHOv83AfzX0uNKWhHRs+y8L6f9Zjou0mWr7x76vJ/cjn0/j101x9Mj/zsn+Pp37W6o3wcy79ng561PS/AdFnnIo+s8L3feZ+os/B4MbMY5renox/N8xnePBE/M94z2fqUBRf1GizIefz0L0+eg5PZk+OHt5qK/SLuTg4sSAAAMjRkNOjRw9JJpNy+PDhrNv1dmlpaZOPKS4uNhcAAJD72ux5coqKimTUqFGybt266DY98Vhvjxs3Lta6AQCA+LXZnhxNDz1NmTJFRo8ebc6No5eQHzt2TKZOnRp31QAAQMzadMiZPHmyvP/++zJv3jxzMsARI0bISy+9dMpkZAAAkH/a9Hlyvqi4zpMDAADs//vdZufkAAAAfBpCDgAAyEmEHAAAkJMIOQAAICcRcgAAQE4i5AAAgJxEyAEAADmJkAMAAHJSmz7j8RcVngdRn1QIAAC0DeG/2591PuO8DjlHjx4113379o27KgAA4HP8O67PfNycvP5aB/2t5YcOHZJOnTqJ53mtmjB1cDp48CBfF2ER7ewObe0G7ewG7dz221lHFx1wevfuLYlE8zNv8ronRzdMnz59rO1f/1J5A9lHO7tDW7tBO7tBO7ftdv60HpwQE48BAEBOIuQAAICcRMixoLi4WObPn2+uYQ/t7A5t7Qbt7AbtnD/tnNcTjwEAQO6iJwcAAOQkQg4AAMhJhBwAAJCTCDkAACAnEXIsWLRokfTv31/atWsnY8eOlS1btsRdpTatvLxcLr74YnNm6p49e8rVV18t+/btyypz4sQJmT59unTv3l06duwokyZNksOHD8dW57ZuwYIF5izgM2fOjG6jjVvPu+++K9/73vdMW7Zv316GDRsm27Zti+7X60HmzZsnZ599trl//Pjx8vbbb8da57YmlUrJPffcIwMGDDBt+OUvf1n+9V//Neu7jmjn0/fKK6/It771LXOmYf0Z8fzzz2fd35I2/eijj+S6664zJwjs0qWLTJs2TT7++GOxQq+uQutZsmSJKioqUr/61a/Unj171A9+8APVpUsXdfjw4bir1maVlZWpJ598Uu3evVvt3LlT/e3f/q3q16+f+vjjj6Myt9xyi+rbt69at26d2rZtm7rkkkvUV7/61Vjr3VZt2bJF9e/fX1144YVqxowZ0e20cev46KOP1Lnnnqu+//3vq82bN6t33nlHvfzyy+qPf/xjVGbBggWqc+fO6vnnn1evv/66+va3v60GDBigjh8/Hmvd25J7771Xde/eXa1atUrt379fLV++XHXs2FE9+OCDURna+fStWbNG/fjHP1b/8R//odOiWrFiRdb9LWnTb37zm2r48OHqtddeU//1X/+lBg4cqK699lplAyGnlY0ZM0ZNnz492k6lUqp3796qvLw81nrlkiNHjpg316ZNm8x2VVWVKiwsNB9iob1795oyFRUVMda07Tl69Kg677zz1Nq1a9XXv/71KOTQxq3nrrvuUpdddlmz9/u+r0pLS9XChQuj23T7FxcXq+eee85RLdu+CRMmqBtvvDHrtokTJ6rrrrvO/Ew7f3GNQ05L2vTNN980j9u6dWtU5sUXX1Se56l3331XtTaGq1rRyZMnZfv27aZ7LvP7sfR2RUVFrHXLJdXV1ea6W7du5lq3eV1dXVa7Dxo0SPr160e7nyY9HDVhwoSsttRo49bzm9/8RkaPHi1/93d/Z4ZfL7roIvn3f//36P79+/dLZWVlVlvr7+jRQ9+0dct99atflXXr1skf/vAHs/3666/Lb3/7W7nqqqvMNu3c+lrSpvpaD1Hp90BIl9f/Vm7evLnV65TXX9DZ2j744AMzDtyrV6+s2/X2W2+9FVu9cu2b4/U8kUsvvVSGDh1qbtNvqqKiIvPGadzu+j60zJIlS2THjh2ydevWU+6jjVvPO++8I4sXL5ZZs2bJP//zP5v2/qd/+ifTvlOmTInas6nPEdq65X70ox+Zb8HWYTyZTJrP5nvvvdfMBdFo59bXkjbV1zrcZyooKDB/tNpod0IO2lxPw+7du81fZGg9Bw8elBkzZsjatWvNhHnYDer6r9h/+7d/M9u6J0e/ph977DETctA6li1bJs8884w8++yzMmTIENm5c6f5A0lPmKWd8wfDVa2oR48e5i+GxitO9HZpaWls9coVt99+u6xatUo2bNggffr0iW7XbauHCquqqrLK0+4tp4ejjhw5IiNHjjR/VenLpk2b5KGHHjI/67/EaOPWoVedDB48OOu2Cy64QA4cOGB+DtuTz5EvZvbs2aY355prrjGr166//nq58847zWpNjXZufS1pU32tP2sy1dfXmxVXNtqdkNOKdHfzqFGjzDhw5l9tenvcuHGx1q0t0/PbdMBZsWKFrF+/3iwJzaTbvLCwMKvd9RJz/Y8G7d4yV1xxhezatcv8tRtedG+D7toPf6aNW4ceam18CgQ9b+Tcc881P+vXt/6wz2xrPeyi5yvQ1i33ySefmHkemfQfofozWaOdW19L2lRf6z+W9B9WIf25rn8veu5Oq2v1qcx5Ti8h1zPJn3rqKTOL/OabbzZLyCsrK+OuWpt16623miWJGzduVO+99150+eSTT7KWN+tl5evXrzfLm8eNG2cu+PwyV1dptHHrLdEvKCgwS5zffvtt9cwzz6gOHTqoX//611nLcPXnxgsvvKDeeOMN9Z3vfIelzadpypQp6pxzzomWkOslzz169FBz5syJytDOn28F5u9//3tz0RHi5z//ufn5z3/+c4vbVC8hv+iii8wpFH7729+aFZ0sIW9DHn74YfOPgT5fjl5Srs8FgM9Pv5Gauuhz54T0G+i2225TXbt2Nf9gfPe73zVBCK0Xcmjj1rNy5Uo1dOhQ8wfRoEGD1OOPP551v16Ke88996hevXqZMldccYXat29fbPVti2pqaszrV38Wt2vXTn3pS18y53epra2NytDOp2/Dhg1Nfh7rUNnSNv3www9NqNHnLSopKVFTp0414ckGT/+v9fuHAAAA4sWcHAAAkJMIOQAAICcRcgAAQE4i5AAAgJxEyAEAADmJkAMAAHISIQcAAOQkQg4AAMhJhBwAAJCTCDkAACAnEXIAAEBOIuQAAADJRf8f49erY+c1DL8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_mses, label='Train MSE')\n",
    "plt.plot(test_mses, label='Test MSE')   \n",
    "# 这两个线重合了，因为是mock的假数据，数据训练效果太好了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc1): Linear(in_features=100, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"模型的保存与加载\"\"\"\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把模型的网络结构和权重保存在一起的\n",
    "import joblib\n",
    "joblib.dump(model, 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把模型的网络结构和权重保存在一起的\n",
    "torch.save(model, 'model.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 怎么把模型的网络结构和权重分开保存呢？\n",
    "# 只保存权重\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "model1 = Model()\n",
    "model1.load_state_dict(torch.load('model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推理\n",
    "def predit(X,model=model):\n",
    "    if not isinstance(X,torch.Tensor):\n",
    "        X = torch.tensor(X)\n",
    "    if X.dim() != 2:\n",
    "        raise ValueError('X must be a 2D tensor')\n",
    "    \n",
    "    # 数据预处理\n",
    "    X = (X - torch.tensor(mu,dtype=torch.float32)) / torch.tensor(sigma,dtype=torch.float32)\n",
    "\n",
    "    # 评估模式\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X)\n",
    "    \n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果为：tensor([[42.6767]])，真实结果为：tensor([46.6686])\n"
     ]
    }
   ],
   "source": [
    "x_to_test,y_to_test = test_dataset[0]\n",
    "y_pred = predit(X=x_to_test.unsqueeze(dim=0))\n",
    "print(f'预测结果为：{y_pred}，真实结果为：{y_to_test}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
